# Neural Network and Adam method

In this folders are written in C++ the structures to build a basic neural network with dense and activation layers and the Adam method, which is s an optimization algorithm for training neural networks that combines the stochastic gradient descent and momentum.  
The code is pretty much self explenatory, I let the reader get into it.